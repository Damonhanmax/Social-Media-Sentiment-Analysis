# -*- coding: utf-8 -*-
"""Social Media Sentiment Analysis2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19E7n75FVjdVGU7Y50whkAtB2o9amXhzr
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd

df = pd.read_csv("sentiment_analysis.csv")
print(df.head())

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(df['text']).toarray()
y = df['sentiment']

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(df['text'])

X = tokenizer.texts_to_sequences(df['text'])
X = pad_sequences(X, maxlen=100)
y = df['sentiment']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=5000, oov_token="<OOV>")
tokenizer.fit_on_texts(df['text'])

X = tokenizer.texts_to_sequences(df['text'])

X = pad_sequences(X, maxlen=100, padding='post', truncating='post')

y = df['sentiment']
if y.dtype == 'object':
    from sklearn.preprocessing import LabelEncoder
    encoder = LabelEncoder()
    y = encoder.fit_transform(y)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense

model = Sequential([
    Embedding(input_dim=5000, output_dim=128, input_length=100),
    LSTM(64, return_sequences=True),
    LSTM(32),
    Dense(1, activation='sigmoid')
])

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))

model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))

loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {accuracy:.4f}")

import os
print("Current working directory:", os.getcwd())
print("Files in directory:", os.listdir())

model.save("sentiment_model.h5")
print("Model saved successfully!")

model_path = "/content/sentiment_model.h5"
model = load_model(model_path)
print("Model loaded successfully!")

from google.colab import files
files.upload()

model.save("sentiment_model.h5")

from tensorflow.keras.models import load_model

model = load_model("sentiment_model.h5")
prediction = model.predict(X_test[:1])
print("Predicted Sentiment:", "Positive" if prediction[0][0] > 0.5 else "Negative")

model = load_model("sentiment_model.h5")
print("Model loaded successfully!")

from tensorflow.keras.models import load_model

model = load_model("sentiment_model.h5")
print("The model is loaded successfully！")

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

print("The model was recompiled successfully！")

loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test set accuracy: {accuracy:.4f}")

predictions = model.predict(X_test[:5])
print("Predict the outcome:", predictions)

loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {accuracy:.4f}")

import numpy as np
import pandas as pd

print(pd.Series(y_train).value_counts())

from tensorflow.keras.layers import Dropout

model.add(Dropout(0.5))

from tensorflow.keras.regularizers import l2

model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=5000, oov_token="<OOV>")
tokenizer.fit_on_texts(df['text'])

X = tokenizer.texts_to_sequences(df['text'])
X = pad_sequences(X, maxlen=100, padding='post', truncating='post')

import numpy as np

embedding_matrix = np.random.randn(5000, 300)

from tensorflow.keras.layers import Embedding

embedding_layer = Embedding(input_dim=5000, output_dim=300, weights=[embedding_matrix], trainable=False)

embedding_layer = Embedding(input_dim=5000, output_dim=300, weights=[embedding_matrix], trainable=False)